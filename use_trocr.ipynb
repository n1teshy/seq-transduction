{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/datasets/ocr_data.zip -d . 1> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import mimetypes\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "# os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "folder = \".cache/\"\n",
    "param_dir = \"/content/drive/MyDrive/trocr\"\n",
    "os.makedirs(param_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"data/train\"\n",
    "VAL_DATA = \"data/test\"\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 2\n",
    "ACCUMULATION_STEPS = 2\n",
    "MEAN_WINDOW = 10\n",
    "MIN_PROGRESS = 0.1\n",
    "MAX_LOSS_DIFF = 0.25\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_losses = deque(maxlen=MEAN_WINDOW)\n",
    "v_losses = deque(maxlen=MEAN_WINDOW)\n",
    "t_loss_sum, v_loss_sum = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRDataset(Dataset):\n",
    "    def __init__(self, folder, sep=\":\"):\n",
    "        self.images = []\n",
    "        for f in glob.glob(os.path.join(folder, \"*\")):\n",
    "            t, _ = mimetypes.guess_type(f)\n",
    "            if t and t.startswith(\"image\"):\n",
    "                self.images.append(f)\n",
    "        self.labels = {}\n",
    "        lbl_path = os.path.join(folder, \"meta/labels.txt\")\n",
    "        for line in open(lbl_path, encoding=\"utf-8\").read().splitlines():\n",
    "            splits = line.split(sep, maxsplit=1)\n",
    "            self.labels[splits[0]] = splits[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx] \n",
    "        return image, self.labels[os.path.basename(image)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        batch = list(zip(*batch))\n",
    "        return list(batch[0]), list(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-printed\")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = processor.tokenizer.eos_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(OCRDataset(TRAIN_DATA), batch_size=BATCH_SIZE, collate_fn=OCRDataset.collate, shuffle=True)\n",
    "val_dataloader = DataLoader(OCRDataset(VAL_DATA), batch_size=BATCH_SIZE, collate_fn=OCRDataset.collate, shuffle=True)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_loss(split, batches=ACCUMULATION_STEPS):\n",
    "    model.eval()\n",
    "    acc_loss = 0\n",
    "    dataloader = train_dataloader if split == \"train\" else val_dataloader\n",
    "    for b_no, (images, labels) in enumerate(dataloader, start=1):\n",
    "        images = [Image.open(img).convert(\"RGB\") for img in images]\n",
    "        pixel_values = processor(images, return_tensors=\"pt\").pixel_values.to(DEVICE)\n",
    "        labels = processor.tokenizer(labels, return_tensors=\"pt\", padding=True).input_ids.to(DEVICE)\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        acc_loss += outputs.loss.item()\n",
    "        if b_no == batches:\n",
    "            break\n",
    "    model.train()\n",
    "    return acc_loss / batches\n",
    "\n",
    "\n",
    "def update_loss_stat(split, loss):\n",
    "    global t_loss_sum, v_loss_sum\n",
    "    losses = t_losses if split == \"train\" else v_losses\n",
    "    first_val = 0\n",
    "    if len(losses) == losses.maxlen:\n",
    "        first_val = losses.popleft()\n",
    "    if split == \"train\":\n",
    "        t_loss_sum += (loss - first_val)\n",
    "    else:\n",
    "        v_loss_sum += (loss - first_val)\n",
    "    losses.append(loss)\n",
    "    return (t_loss_sum if split == \"train\" else v_loss_sum) / len(losses)\n",
    "\n",
    "\n",
    "def save_model(mt_loss, mv_loss, folder=param_dir):\n",
    "    name = \"trocr_%.4f_%.4f.pth\" % (mt_loss, mv_loss)\n",
    "    torch.save(model.state_dict(), os.path.join(folder, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_no in range(1, EPOCHS + 1):\n",
    "    for b_no, (images, labels) in enumerate(train_dataloader, start=1):\n",
    "        images = [Image.open(img).convert(\"RGB\") for img in images]\n",
    "        pixel_values = processor(images, return_tensors=\"pt\").pixel_values.to(DEVICE)\n",
    "        labels = processor.tokenizer(labels, return_tensors=\"pt\", padding=True).input_ids.to(DEVICE)\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss = loss / ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        if b_no % ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            t_loss, v_loss = get_loss(\"train\"), get_loss(\"val\")\n",
    "            mt_loss = update_loss_stat(\"train\", t_loss)\n",
    "            mv_loss = update_loss_stat(\"val\", v_loss)\n",
    "            print(\"train: (%.4f | %.4f), val: (%.4f | %.4f)\" % (t_loss, mt_loss, v_loss, mv_loss))\n",
    "        if (e_no > 1 or len(t_losses) >= MEAN_WINDOW) and mv_loss - v_loss >= MIN_PROGRESS:\n",
    "            if abs(mt_loss - mv_loss) > MAX_LOSS_DIFF:\n",
    "                overfitting = mt_loss - mv_loss > 0\n",
    "                word = \"overfitting\" if overfitting else \"underfitting\"\n",
    "                print(\"the model seems to be %s\" % (word, ))\n",
    "            else:\n",
    "                save_model(mt_loss, mv_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(DEVICE)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
